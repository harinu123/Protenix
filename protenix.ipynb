{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3100633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T01:56:04.470686Z",
     "iopub.status.busy": "2025-04-16T01:56:04.470407Z",
     "iopub.status.idle": "2025-04-16T01:56:04.474842Z",
     "shell.execute_reply": "2025-04-16T01:56:04.474198Z"
    },
    "papermill": {
     "duration": 0.00997,
     "end_time": "2025-04-16T01:56:04.475998",
     "exception": false,
     "start_time": "2025-04-16T01:56:04.466028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_TYPE='protenix'\n",
    "VALIDATION=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd3300f",
   "metadata": {
    "papermill": {
     "duration": 0.002622,
     "end_time": "2025-04-16T01:56:04.481740",
     "exception": false,
     "start_time": "2025-04-16T01:56:04.479118",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e34a7582",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T01:56:04.488088Z",
     "iopub.status.busy": "2025-04-16T01:56:04.487883Z",
     "iopub.status.idle": "2025-04-16T01:56:04.605005Z",
     "shell.execute_reply": "2025-04-16T01:56:04.604009Z"
    },
    "papermill": {
     "duration": 0.122056,
     "end_time": "2025-04-16T01:56:04.606721",
     "exception": false,
     "start_time": "2025-04-16T01:56:04.484665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --no-deps protenix\n",
    "# !pip install biopython\n",
    "# !pip install ml-collections\n",
    "# !pip install biotite==1.0.1\n",
    "# !pip install rdkit\n",
    "\n",
    "if MODEL_TYPE=='protenix' and VALIDATION:\n",
    "    !pip install --no-deps protenix\n",
    "    !pip install biopython\n",
    "    !pip install ml-collections\n",
    "    !pip install biotite==1.0.1\n",
    "    !pip install rdkit\n",
    "!export PROTENIX_DATA_ROOT_DIR=/kaggle/input/protenix-checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2abf8b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T01:56:04.614139Z",
     "iopub.status.busy": "2025-04-16T01:56:04.613865Z",
     "iopub.status.idle": "2025-04-16T01:56:04.962082Z",
     "shell.execute_reply": "2025-04-16T01:56:04.961217Z"
    },
    "papermill": {
     "duration": 0.353473,
     "end_time": "2025-04-16T01:56:04.963567",
     "exception": false,
     "start_time": "2025-04-16T01:56:04.610094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "components.v20240608.cif\t\tmodel_v0.2.0.pt\r\n",
      "components.v20240608.cif.rdkit_mol.pkl\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir /af3-dev \n",
    "! ln -s /kaggle/input/protenix-checkpoints /af3-dev/release_data\n",
    "! ls /af3-dev/release_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7cefb57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T01:56:04.971102Z",
     "iopub.status.busy": "2025-04-16T01:56:04.970831Z",
     "iopub.status.idle": "2025-04-16T01:56:04.974451Z",
     "shell.execute_reply": "2025-04-16T01:56:04.973670Z"
    },
    "papermill": {
     "duration": 0.008684,
     "end_time": "2025-04-16T01:56:04.975760",
     "exception": false,
     "start_time": "2025-04-16T01:56:04.967076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VALIDATION=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8574873b",
   "metadata": {
    "papermill": {
     "duration": 0.002694,
     "end_time": "2025-04-16T01:56:04.981517",
     "exception": false,
     "start_time": "2025-04-16T01:56:04.978823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bf29b59",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-16T01:56:04.988093Z",
     "iopub.status.busy": "2025-04-16T01:56:04.987887Z",
     "iopub.status.idle": "2025-04-16T01:56:09.517750Z",
     "shell.execute_reply": "2025-04-16T01:56:09.516794Z"
    },
    "papermill": {
     "duration": 4.534703,
     "end_time": "2025-04-16T01:56:09.519132",
     "exception": false,
     "start_time": "2025-04-16T01:56:04.984429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT OK !!!!\n"
     ]
    }
   ],
   "source": [
    "import Bio\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "from Bio.PDB import Atom, Model, Chain, Residue, Structure, PDBParser\n",
    "from Bio import SeqIO\n",
    "import os, sys\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "time0=time.time()\n",
    "\n",
    "print('IMPORT OK !!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd5928a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T01:56:09.526977Z",
     "iopub.status.busy": "2025-04-16T01:56:09.526592Z",
     "iopub.status.idle": "2025-04-16T01:56:09.642956Z",
     "shell.execute_reply": "2025-04-16T01:56:09.641950Z"
    },
    "papermill": {
     "duration": 0.121682,
     "end_time": "2025-04-16T01:56:09.644307",
     "exception": false,
     "start_time": "2025-04-16T01:56:09.522625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHON /usr/bin/python3\n",
      "HELPER OK!!!\n"
     ]
    }
   ],
   "source": [
    "PYTHON = sys.executable\n",
    "print('PYTHON',PYTHON)\n",
    "\n",
    "RHONET_DIR=\\\n",
    "'/kaggle/input/data-for-demo-for-rhofold-plus-with-kaggle-msa/RhoFold-main'\n",
    "#'<your downloaded rhofold repo>/RhoFold-main'\n",
    "\n",
    "USALIGN = \\\n",
    "'/kaggle/working//USalign'\n",
    "#'<your us align path>/USalign'\n",
    "\n",
    "os.system('cp /kaggle/input/usalign/USalign /kaggle/working/')\n",
    "os.system('sudo chmod u+x /kaggle/working//USalign')\n",
    "sys.path.append(RHONET_DIR)\n",
    "\n",
    "\n",
    "DATA_KAGGLE_DIR = '/kaggle/input/stanford-rna-3d-folding'\n",
    "\n",
    "\n",
    "# helper ----\n",
    "class dotdict(dict):\n",
    "\t__setattr__ = dict.__setitem__\n",
    "\t__delattr__ = dict.__delitem__\n",
    "\n",
    "\tdef __getattr__(self, name):\n",
    "\t\ttry:\n",
    "\t\t\treturn self[name]\n",
    "\t\texcept KeyError:\n",
    "\t\t\traise AttributeError(name)\n",
    "\n",
    "# visualisation helper ----\n",
    "def set_aspect_equal(ax):\n",
    "\tx_limits = ax.get_xlim()\n",
    "\ty_limits = ax.get_ylim()\n",
    "\tz_limits = ax.get_zlim()\n",
    "\n",
    "\t# Compute the mean of each axis\n",
    "\tx_middle = np.mean(x_limits)\n",
    "\ty_middle = np.mean(y_limits)\n",
    "\tz_middle = np.mean(z_limits)\n",
    "\n",
    "\t# Compute the max range across all axes\n",
    "\tmax_range = max(x_limits[1] - x_limits[0],\n",
    "\t\t\t\t\ty_limits[1] - y_limits[0],\n",
    "\t\t\t\t\tz_limits[1] - z_limits[0]) / 2.0\n",
    "\n",
    "\t# Set the new limits to ensure equal scaling\n",
    "\tax.set_xlim(x_middle - max_range, x_middle + max_range)\n",
    "\tax.set_ylim(y_middle - max_range, y_middle + max_range)\n",
    "\tax.set_zlim(z_middle - max_range, z_middle + max_range)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# xyz df helper --------------------\n",
    "def get_truth_df(target_id):\n",
    "    truth_df = LABEL_DF[LABEL_DF['target_id'] == target_id]\n",
    "    truth_df = truth_df.reset_index(drop=True)\n",
    "    return truth_df\n",
    "\n",
    "def parse_output_to_df(output, seq, target_id):\n",
    "    df = []\n",
    "    chain_data = []\n",
    "    for i, res in enumerate(seq):\n",
    "        d=dict(ID = target_id,\n",
    "                    resname=res,\n",
    "                    resid=i+1)\n",
    "        for n in range(len(output)):\n",
    "            d={**d, f'x_{n+1}': round(output[n,i,0].item(),3),\n",
    "                     f'y_{n+1}': round(output[n,i,1].item(),3),\n",
    "                     f'z_{n+1}': round(output[n,i,2].item(),3)}\n",
    "        chain_data.append(d)\n",
    "\n",
    "    if len(chain_data)!=0:\n",
    "        chain_df = pd.DataFrame(chain_data)\n",
    "        df.append(chain_df)\n",
    "        ##print(chain_df)\n",
    "    return df\n",
    "\n",
    "def parse_pdb_to_df(pdb_file, target_id):\n",
    "    parser = PDBParser()\n",
    "    structure = parser.get_structure('', pdb_file)\n",
    "\n",
    "    df = []\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            print(chain)\n",
    "            chain_data = []\n",
    "            for residue in chain:\n",
    "                # print(residue)\n",
    "                if residue.get_resname() in ['A', 'U', 'G', 'C']:\n",
    "                    # Check if the residue has a C1' atom\n",
    "                    if 'C1\\'' in residue:\n",
    "                        atom = residue['C1\\'']\n",
    "                        xyz = atom.get_coord()\n",
    "                        resname = residue.get_resname()\n",
    "                        resid = residue.get_id()[1]\n",
    "\n",
    "                        #todo detect discontinous: resid = prev_resid+1\n",
    "                        #ID\tresname\tresid\tx_1\ty_1\tz_1\n",
    "                        chain_data.append(dict(\n",
    "                            ID = target_id+'_'+str(resid),\n",
    "                            resname=resname,\n",
    "                            resid=resid,\n",
    "                            x_1=xyz[0],\n",
    "                            y_1=xyz[1],\n",
    "                            z_1=xyz[2],\n",
    "                        ))\n",
    "                        ##print(f\"Residue {resname} {resid}, Atom: {atom.get_name()}, xyz: {xyz}\")\n",
    "\n",
    "            if len(chain_data)!=0:\n",
    "                chain_df = pd.DataFrame(chain_data)\n",
    "                df.append(chain_df)\n",
    "                ##print(chain_df)\n",
    "    return df\n",
    "\n",
    "# usalign helper --------------------\n",
    "def write_target_line(\n",
    "    atom_name, atom_serial, residue_name, chain_id, residue_num, x_coord, y_coord, z_coord, occupancy=1.0, b_factor=0.0, atom_type='P'\n",
    "):\n",
    "    \"\"\"\n",
    "    Writes a single line of PDB format based on provided atom information.\n",
    "\n",
    "    Args:\n",
    "        atom_name (str): Name of the atom (e.g., \"N\", \"CA\").\n",
    "        atom_serial (int): Atom serial number.\n",
    "        residue_name (str): Residue name (e.g., \"ALA\").\n",
    "        chain_id (str): Chain identifier.\n",
    "        residue_num (int): Residue number.\n",
    "        x_coord (float): X coordinate.\n",
    "        y_coord (float): Y coordinate.\n",
    "        z_coord (float): Z coordinate.\n",
    "        occupancy (float, optional): Occupancy value (default: 1.0).\n",
    "        b_factor (float, optional): B-factor value (default: 0.0).\n",
    "\n",
    "    Returns:\n",
    "        str: A single line of PDB string.\n",
    "    \"\"\"\n",
    "    return f'ATOM  {atom_serial:>5d}  {atom_name:<5s} {residue_name:<3s} {residue_num:>3d}    {x_coord:>8.3f}{y_coord:>8.3f}{z_coord:>8.3f}{occupancy:>6.2f}{b_factor:>6.2f}           {atom_type}\\n'\n",
    "\n",
    "def write_xyz_to_pdb(df, pdb_file, xyz_id = 1):\n",
    "    resolved_cnt = 0\n",
    "    with open(pdb_file, 'w') as target_file:\n",
    "        for _, row in df.iterrows():\n",
    "            x_coord = row[f'x_{xyz_id}']\n",
    "            y_coord = row[f'y_{xyz_id}']\n",
    "            z_coord = row[f'z_{xyz_id}']\n",
    "\n",
    "            if x_coord > -1e17 and y_coord > -1e17 and z_coord > -1e17:\n",
    "                resolved_cnt += 1\n",
    "                target_line = write_target_line(\n",
    "                    atom_name=\"C1'\",\n",
    "                    atom_serial=int(row['resid']),\n",
    "                    residue_name=row['resname'],\n",
    "                    chain_id='0',\n",
    "                    residue_num=int(row['resid']),\n",
    "                    x_coord=x_coord,\n",
    "                    y_coord=y_coord,\n",
    "                    z_coord=z_coord,\n",
    "                    atom_type='C',\n",
    "                )\n",
    "                target_file.write(target_line)\n",
    "    return resolved_cnt\n",
    "\n",
    "def parse_usalign_for_tm_score(output):\n",
    "    # Extract TM-score based on length of reference structure (second)\n",
    "    tm_score_match = re.findall(r'TM-score=\\s+([\\d.]+)', output)[1]\n",
    "    if not tm_score_match:\n",
    "        raise ValueError('No TM score found')\n",
    "    return float(tm_score_match)\n",
    "\n",
    "def parse_usalign_for_transform(output):\n",
    "    # Locate the rotation matrix section\n",
    "    matrix_lines = []\n",
    "    found_matrix = False\n",
    "\n",
    "    for line in output.splitlines():\n",
    "        if \"The rotation matrix to rotate Structure_1 to Structure_2\" in line:\n",
    "            found_matrix = True\n",
    "        elif found_matrix and re.match(r'^\\d+\\s+[-\\d.]+\\s+[-\\d.]+\\s+[-\\d.]+\\s+[-\\d.]+$', line):\n",
    "            matrix_lines.append(line)\n",
    "        elif found_matrix and not line.strip():\n",
    "            break  # Stop parsing if an empty line is encountered after the matrix\n",
    "\n",
    "    # Parse the rotation matrix values\n",
    "    rotation_matrix = []\n",
    "    for line in matrix_lines:\n",
    "        parts = line.split()\n",
    "        row_values = list(map(float, parts[1:]))  # Skip the first column (index)\n",
    "        rotation_matrix.append(row_values)\n",
    "\n",
    "    return np.array(rotation_matrix)\n",
    "\n",
    "def call_usalign(predict_df, truth_df, verbose=1):\n",
    "    truth_pdb = '~truth.pdb'\n",
    "    predict_pdb = '~predict.pdb'\n",
    "    write_xyz_to_pdb(predict_df, predict_pdb, xyz_id=1)\n",
    "    write_xyz_to_pdb(truth_df, truth_pdb, xyz_id=1)\n",
    "\n",
    "    command = f'{USALIGN} {predict_pdb} {truth_pdb} -atom \" C1\\'\" -m -'\n",
    "    output = os.popen(command).read()\n",
    "    if verbose==1:\n",
    "        print(output)\n",
    "    tm_score = parse_usalign_for_tm_score(output)\n",
    "    transform = parse_usalign_for_transform(output)\n",
    "    return tm_score, transform\n",
    "\n",
    "print('HELPER OK!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a9a53c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T01:56:09.651698Z",
     "iopub.status.busy": "2025-04-16T01:56:09.651442Z",
     "iopub.status.idle": "2025-04-16T01:56:14.690258Z",
     "shell.execute_reply": "2025-04-16T01:56:14.689415Z"
    },
    "papermill": {
     "duration": 5.044302,
     "end_time": "2025-04-16T01:56:14.692036",
     "exception": false,
     "start_time": "2025-04-16T01:56:09.647734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL_TYPE=='protenix':\n",
    "    \n",
    "    \n",
    "    from runner.batch_inference import get_default_runner\n",
    "    from runner.inference import update_inference_configs, InferenceRunner\n",
    "\n",
    "    from protenix.data.infer_data_pipeline import InferenceDataset\n",
    "\n",
    "    np.random.seed(0)\n",
    "    torch.random.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "    class DictDataset(InferenceDataset):\n",
    "        def __init__(\n",
    "            self,\n",
    "            seq_list: list,\n",
    "            dump_dir: str,\n",
    "            id_list: list = None,\n",
    "            use_msa: bool = False,\n",
    "        ) -> None:\n",
    "\n",
    "            self.dump_dir = dump_dir\n",
    "            self.use_msa = use_msa\n",
    "            if isinstance(id_list,type(None)):\n",
    "                self.inputs = [{\"sequences\": \n",
    "                                [{\"rnaSequence\": \n",
    "                                  {\"sequence\": seq, \n",
    "                                   \"count\": 1}}],\n",
    "                                \"name\": \"query\"} for seq in seq_list]\n",
    "            else:\n",
    "                self.inputs = [{\"sequences\": \n",
    "                                [{\"rnaSequence\": \n",
    "                                  {\"sequence\": seq, \n",
    "                                   \"count\": 1}}],\n",
    "                                \"name\": i} for i, seq in zip(id_list,seq_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2baf09e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T01:56:14.702774Z",
     "iopub.status.busy": "2025-04-16T01:56:14.702209Z",
     "iopub.status.idle": "2025-04-16T01:56:30.191278Z",
     "shell.execute_reply": "2025-04-16T01:56:30.190520Z"
    },
    "papermill": {
     "duration": 15.494552,
     "end_time": "2025-04-16T01:56:30.192950",
     "exception": false,
     "start_time": "2025-04-16T01:56:14.698398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scheduler 16.0\n",
      "inference scheduler 16.0\n",
      "Diffusion Module has 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/runner/inference.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, self.device)\n"
     ]
    }
   ],
   "source": [
    "if MODEL_TYPE=='protenix':\n",
    "\n",
    "    from configs.configs_base import configs as configs_base\n",
    "    from configs.configs_data import data_configs\n",
    "    from configs.configs_inference import inference_configs\n",
    "    from protenix.config.config import parse_configs\n",
    "\n",
    "    configs_base[\"use_deepspeed_evo_attention\"] = (\n",
    "    os.environ.get(\"USE_DEEPSPEED_EVO_ATTENTION\", False) == \"true\")\n",
    "    configs_base[\"model\"][\"N_cycle\"] = 10 #10\n",
    "    configs_base[\"sample_diffusion\"][\"N_sample\"] = (1 if VALIDATION else 4)\n",
    "    configs_base[\"sample_diffusion\"][\"N_step\"] = 200\n",
    "    inference_configs['load_checkpoint_path']='/kaggle/input/protenix-checkpoints/model_v0.2.0.pt'\n",
    "    # inference_configs['load_checkpoint_path']='/kaggle/input/protenix_version1/pytorch/default/1/model_v1.pt'\n",
    "\n",
    "    configs = {**configs_base, **{\"data\": data_configs}, **inference_configs}\n",
    "\n",
    "    configs = parse_configs(\n",
    "            configs=configs,\n",
    "            fill_required_with_null=True,\n",
    "        )\n",
    "    \n",
    "    runner=InferenceRunner(configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9f9659e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T01:56:30.201717Z",
     "iopub.status.busy": "2025-04-16T01:56:30.201380Z",
     "iopub.status.idle": "2025-04-16T01:56:30.205248Z",
     "shell.execute_reply": "2025-04-16T01:56:30.204569Z"
    },
    "papermill": {
     "duration": 0.009733,
     "end_time": "2025-04-16T01:56:30.206578",
     "exception": false,
     "start_time": "2025-04-16T01:56:30.196845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if VALIDATION:\n",
    "    LABEL_DF = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_labels.csv')\n",
    "    LABEL_DF['target_id'] = LABEL_DF['ID'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "    train_df=pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_sequences.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89257bda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T01:56:30.214172Z",
     "iopub.status.busy": "2025-04-16T01:56:30.213924Z",
     "iopub.status.idle": "2025-04-16T01:56:30.220654Z",
     "shell.execute_reply": "2025-04-16T01:56:30.219886Z"
    },
    "papermill": {
     "duration": 0.011932,
     "end_time": "2025-04-16T01:56:30.221964",
     "exception": false,
     "start_time": "2025-04-16T01:56:30.210032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if MODEL_TYPE=='protenix' and VALIDATION:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")  \n",
    "    \n",
    "    train_df['protenix_tm_score']=None\n",
    "    dataset = DictDataset(train_df.sequence, dump_dir='output', id_list=train_df.target_id, use_msa=False)\n",
    "    num_data = len(dataset)\n",
    "    for i, seq in tqdm(enumerate(train_df.sequence),total=num_data):\n",
    "        if train_df.loc[i,'protenix_tm_score']!=None:\n",
    "            continue\n",
    "        if len(seq)>300:\n",
    "            continue\n",
    "        target_id = train_df.loc[i,'target_id']\n",
    "        truth_df = get_truth_df(target_id)\n",
    "        if sum(~np.isnan(truth_df.x_1))<3:\n",
    "            continue\n",
    "        data, atom_array, data_error_message=dataset[i]\n",
    "        if data_error_message!='':\n",
    "            continue\n",
    "        new_configs = update_inference_configs(configs, data[\"N_token\"].item())\n",
    "        runner.update_model_configs(new_configs)\n",
    "        prediction = runner.predict(data)\n",
    "        prediction=prediction['coordinate'][:,data['input_feature_dict']['atom_to_tokatom_idx']==12]       \n",
    "        result = parse_output_to_df(prediction[:1], seq, target_id)[0]\n",
    "        try:\n",
    "            tm_score, transform = call_usalign(result, truth_df, verbose=0)\n",
    "            train_df.loc[i,'protenix_tm_score']=tm_score\n",
    "        except:\n",
    "            pass\n",
    "        if (time.time()-time0)>(12*3600-360):\n",
    "            break\n",
    "    train_df.to_csv('tm_scores.csv', index=False)\n",
    "    print(train_df.protenix_tm_score.mean())\n",
    "    display(train_df.protenix_tm_score.hist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c3104dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T01:56:30.230282Z",
     "iopub.status.busy": "2025-04-16T01:56:30.230074Z",
     "iopub.status.idle": "2025-04-16T02:26:20.192156Z",
     "shell.execute_reply": "2025-04-16T02:26:20.191226Z"
    },
    "papermill": {
     "duration": 1789.968179,
     "end_time": "2025-04-16T02:26:20.193747",
     "exception": false,
     "start_time": "2025-04-16T01:56:30.225568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [29:49<00:00, 149.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>z_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>z_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1107_1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>-15.920</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-9.981</td>\n",
       "      <td>-5.159</td>\n",
       "      <td>12.091</td>\n",
       "      <td>6.943</td>\n",
       "      <td>-1.185</td>\n",
       "      <td>-6.415</td>\n",
       "      <td>-4.031</td>\n",
       "      <td>1.194</td>\n",
       "      <td>15.283</td>\n",
       "      <td>10.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R1107_2</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.705</td>\n",
       "      <td>-3.894</td>\n",
       "      <td>-6.542</td>\n",
       "      <td>-9.765</td>\n",
       "      <td>9.041</td>\n",
       "      <td>8.397</td>\n",
       "      <td>-3.769</td>\n",
       "      <td>-3.808</td>\n",
       "      <td>-8.472</td>\n",
       "      <td>-4.479</td>\n",
       "      <td>16.236</td>\n",
       "      <td>9.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R1107_3</td>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>-9.614</td>\n",
       "      <td>-8.423</td>\n",
       "      <td>-4.701</td>\n",
       "      <td>-14.476</td>\n",
       "      <td>6.174</td>\n",
       "      <td>6.990</td>\n",
       "      <td>-8.246</td>\n",
       "      <td>-1.061</td>\n",
       "      <td>-10.911</td>\n",
       "      <td>-9.217</td>\n",
       "      <td>16.432</td>\n",
       "      <td>6.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R1107_4</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>-7.058</td>\n",
       "      <td>-13.441</td>\n",
       "      <td>-5.980</td>\n",
       "      <td>-17.867</td>\n",
       "      <td>3.747</td>\n",
       "      <td>3.175</td>\n",
       "      <td>-13.128</td>\n",
       "      <td>1.469</td>\n",
       "      <td>-10.390</td>\n",
       "      <td>-11.855</td>\n",
       "      <td>15.257</td>\n",
       "      <td>1.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R1107_5</td>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.897</td>\n",
       "      <td>-16.878</td>\n",
       "      <td>-10.215</td>\n",
       "      <td>-19.143</td>\n",
       "      <td>1.691</td>\n",
       "      <td>-1.810</td>\n",
       "      <td>-17.406</td>\n",
       "      <td>3.633</td>\n",
       "      <td>-7.701</td>\n",
       "      <td>-12.349</td>\n",
       "      <td>12.831</td>\n",
       "      <td>-3.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>R1190_114</td>\n",
       "      <td>U</td>\n",
       "      <td>114</td>\n",
       "      <td>19.829</td>\n",
       "      <td>-15.041</td>\n",
       "      <td>-11.275</td>\n",
       "      <td>20.605</td>\n",
       "      <td>12.327</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-7.734</td>\n",
       "      <td>-17.693</td>\n",
       "      <td>-10.846</td>\n",
       "      <td>13.907</td>\n",
       "      <td>21.261</td>\n",
       "      <td>-9.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>R1190_115</td>\n",
       "      <td>U</td>\n",
       "      <td>115</td>\n",
       "      <td>24.640</td>\n",
       "      <td>-13.244</td>\n",
       "      <td>-11.523</td>\n",
       "      <td>19.475</td>\n",
       "      <td>8.516</td>\n",
       "      <td>-3.971</td>\n",
       "      <td>-6.186</td>\n",
       "      <td>-15.639</td>\n",
       "      <td>-15.348</td>\n",
       "      <td>11.795</td>\n",
       "      <td>17.941</td>\n",
       "      <td>-13.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>R1190_116</td>\n",
       "      <td>U</td>\n",
       "      <td>116</td>\n",
       "      <td>30.213</td>\n",
       "      <td>-12.972</td>\n",
       "      <td>-11.077</td>\n",
       "      <td>17.815</td>\n",
       "      <td>5.790</td>\n",
       "      <td>-8.558</td>\n",
       "      <td>-4.072</td>\n",
       "      <td>-15.297</td>\n",
       "      <td>-20.487</td>\n",
       "      <td>8.492</td>\n",
       "      <td>15.717</td>\n",
       "      <td>-17.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>R1190_117</td>\n",
       "      <td>U</td>\n",
       "      <td>117</td>\n",
       "      <td>35.067</td>\n",
       "      <td>-15.258</td>\n",
       "      <td>-11.584</td>\n",
       "      <td>17.761</td>\n",
       "      <td>4.761</td>\n",
       "      <td>-14.001</td>\n",
       "      <td>-3.292</td>\n",
       "      <td>-17.142</td>\n",
       "      <td>-25.626</td>\n",
       "      <td>6.291</td>\n",
       "      <td>16.664</td>\n",
       "      <td>-21.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>R1190_118</td>\n",
       "      <td>U</td>\n",
       "      <td>118</td>\n",
       "      <td>37.703</td>\n",
       "      <td>-19.118</td>\n",
       "      <td>-13.727</td>\n",
       "      <td>20.408</td>\n",
       "      <td>5.435</td>\n",
       "      <td>-18.432</td>\n",
       "      <td>-5.121</td>\n",
       "      <td>-20.417</td>\n",
       "      <td>-29.303</td>\n",
       "      <td>6.309</td>\n",
       "      <td>19.571</td>\n",
       "      <td>-26.410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2515 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID resname  resid     x_1     y_1     z_1     x_2     y_2  \\\n",
       "0       R1107_1       G      1 -15.920  -0.520  -9.981  -5.159  12.091   \n",
       "1       R1107_2       G      2 -12.705  -3.894  -6.542  -9.765   9.041   \n",
       "2       R1107_3       G      3  -9.614  -8.423  -4.701 -14.476   6.174   \n",
       "3       R1107_4       G      4  -7.058 -13.441  -5.980 -17.867   3.747   \n",
       "4       R1107_5       G      5  -4.897 -16.878 -10.215 -19.143   1.691   \n",
       "...         ...     ...    ...     ...     ...     ...     ...     ...   \n",
       "2510  R1190_114       U    114  19.829 -15.041 -11.275  20.605  12.327   \n",
       "2511  R1190_115       U    115  24.640 -13.244 -11.523  19.475   8.516   \n",
       "2512  R1190_116       U    116  30.213 -12.972 -11.077  17.815   5.790   \n",
       "2513  R1190_117       U    117  35.067 -15.258 -11.584  17.761   4.761   \n",
       "2514  R1190_118       U    118  37.703 -19.118 -13.727  20.408   5.435   \n",
       "\n",
       "         z_2     x_3     y_3     z_3     x_4     y_4     z_4  \n",
       "0      6.943  -1.185  -6.415  -4.031   1.194  15.283  10.491  \n",
       "1      8.397  -3.769  -3.808  -8.472  -4.479  16.236   9.920  \n",
       "2      6.990  -8.246  -1.061 -10.911  -9.217  16.432   6.545  \n",
       "3      3.175 -13.128   1.469 -10.390 -11.855  15.257   1.644  \n",
       "4     -1.810 -17.406   3.633  -7.701 -12.349  12.831  -3.364  \n",
       "...      ...     ...     ...     ...     ...     ...     ...  \n",
       "2510  -0.756  -7.734 -17.693 -10.846  13.907  21.261  -9.628  \n",
       "2511  -3.971  -6.186 -15.639 -15.348  11.795  17.941 -13.015  \n",
       "2512  -8.558  -4.072 -15.297 -20.487   8.492  15.717 -17.048  \n",
       "2513 -14.001  -3.292 -17.142 -25.626   6.291  16.664 -21.863  \n",
       "2514 -18.432  -5.121 -20.417 -29.303   6.309  19.571 -26.410  \n",
       "\n",
       "[2515 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if MODEL_TYPE=='protenix' and not VALIDATION:\n",
    "    test_df=pd.read_csv('/kaggle/input/stanford-rna-3d-folding/test_sequences.csv')\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")  \n",
    "    \n",
    "    dataset = DictDataset(test_df.sequence, dump_dir='output', id_list=test_df.target_id, use_msa=False)\n",
    "    num_data = len(dataset)\n",
    "    for i, seq in tqdm(enumerate(test_df.sequence),total=num_data):\n",
    "        try:\n",
    "            data, atom_array, data_error_message=dataset[i]\n",
    "            target_id = data[\"sample_name\"]\n",
    "            assert target_id==test_df.target_id[i]\n",
    "            assert data_error_message==''\n",
    "            \n",
    "            new_configs = update_inference_configs(configs, data[\"N_token\"].item())\n",
    "            runner.update_model_configs(new_configs)\n",
    "            prediction = runner.predict(data)\n",
    "            prediction=prediction['coordinate'][:,data['input_feature_dict']['atom_to_tokatom_idx']==12]\n",
    "\n",
    "            result = parse_output_to_df(prediction, seq, target_id)[0]\n",
    "        except:\n",
    "            target_id==test_df.target_id[i]\n",
    "            print('Failed to predict', target_id)\n",
    "            result=pd.DataFrame(columns=['ID', 'resname', 'resid', \n",
    "                                         'x_1', 'y_1', 'z_1', \n",
    "                                         'x_2', 'y_2', 'z_2',\n",
    "                                         'x_3', 'y_3', 'z_3', \n",
    "                                         'x_4', 'y_4', 'z_4', \n",
    "                                         'x_5', 'y_5', 'z_5'], \n",
    "                                         data=[[target_id, x, j+1] + [0.0]*15 for j, x in enumerate(seq)])\n",
    "            \n",
    "        result['ID']=result.apply(lambda x: x.ID + '_' + str(x.resid), axis=1)\n",
    "        result.to_csv('submission.csv', index=False, mode='a', header=(i==0))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    display(pd.read_csv('submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f62e69",
   "metadata": {
    "papermill": {
     "duration": 0.004262,
     "end_time": "2025-04-16T02:26:20.202616",
     "exception": false,
     "start_time": "2025-04-16T02:26:20.198354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11553390,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 6742586,
     "sourceId": 10855324,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6933267,
     "sourceId": 11118830,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 224830487,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 233931194,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 303766,
     "modelInstanceId": 282902,
     "sourceId": 338324,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1821.592529,
   "end_time": "2025-04-16T02:26:23.285584",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-16T01:56:01.693055",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
